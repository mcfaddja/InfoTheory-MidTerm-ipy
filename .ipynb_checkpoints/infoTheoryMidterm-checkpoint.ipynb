{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Theory Mid-Term\n",
    "Jonathan McFadden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 (a)\n",
    "\n",
    "## Definitions\n",
    "\n",
    "Prior to beginning our work, we load the requiste packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and start a timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0s = []\n",
    "\n",
    "tTMP = []\n",
    "tTMP.append(time.time())\n",
    "tTMP.append(\"Start timer\")\n",
    "\n",
    "t0s.append(tTMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also load all 26 letters (*in lower case*) into an array for later use.  This is done by importing a text file containing these letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('LowerCaseAlphabet.txt', 'r') as myFile:\n",
    "    lowerAlpha = myFile.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then stripping the return characters (*\\n*) from each line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(lowerAlpha)):\n",
    "    lowerAlpha[i] = lowerAlpha[i].replace('\\n','')\n",
    "\n",
    "lowerAlphaB = ''.join(str(x) for x in lowerAlpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we check to see if the alphabet imported properly,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "print(lowerAlphaB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as well as create an upper case version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "upperAlpha = []\n",
    "for x in lowerAlpha:\n",
    "    upperAlpha.append(x.upper())\n",
    "    \n",
    "upperAlphaB = ''.join(str(x) for x in upperAlpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and check it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABCDEFGHIJKLMNOPQRSTUVWXYZ\n"
     ]
    }
   ],
   "source": [
    "print(upperAlphaB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load File\n",
    "\n",
    "First we start another timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tTMP = []\n",
    "tTMP.append(time.time())\n",
    "tTMP.append(\"Load File timer\")\n",
    "\n",
    "t0s.append(tTMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we begin our work by loading the text from the source file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Text-Files/sawyer-ascii.txt', 'r') as myFile:\n",
    "    tempData = myFile.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we get some basic information about the data imported from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8807\n"
     ]
    }
   ],
   "source": [
    "print(len(tempData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, convert the array of strings to a single string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ''.join(str(x) for x in tempData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then find and store the length of the resulting string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402665\n"
     ]
    }
   ],
   "source": [
    "charCNT = len(data)\n",
    "print(charCNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the length compare it to the combined length of all the strings in the initial array we got from importing the text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402665\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for x in tempData:\n",
    "    cnt = cnt + len(x)\n",
    "\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the character counts are accurate, we can proceed.\n",
    "\n",
    "\n",
    "## Get Character List\n",
    "\n",
    "First, we start yet another timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tTMP = []\n",
    "tTMP.append(time.time())\n",
    "tTMP.append(\"Get Character List timer\")\n",
    "\n",
    "t0s.append(tTMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will obtain a list of all characters occuring in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', '~', 'i', 'G', 'M', 'c', '*', '(', 'T', '!', \"'\", ':', '3', '/', ']', 'B', '8', '@', 'u', 'v', 'U', '0', '+', 'e', '\"', 'I', 'd', ';', 'P', 'W', '6', 'J', 'Q', 'E', 'N', 'z', '5', '&', 'w', 'p', 'R', ',', '>', 'k', 'A', 'm', 'K', '_', 'L', '<', 'f', '4', '-', 'n', 'b', '7', 'O', 'q', 'j', '%', 'l', 'a', 'D', '\\n', 'h', '.', 't', 'X', '?', '1', 'y', ')', '9', '#', 'o', 'g', '$', 'S', ' ', 'r', 's', 'F', 'Y', 'H', 'x', 'V', '[', '2']\n",
      "C~iGMc*(T!':3/]B8@uvU0+e\"Id;PW6JQENz5&wpR,>kAmK_L<f4-nb7Oqj%laD\n",
      "h.tX?1y)9#og$S rsFYHxV[2\n"
     ]
    }
   ],
   "source": [
    "myChars = list(set(data))\n",
    "\n",
    "myChars2 = ''.join(str(x) for x in myChars)\n",
    "print(myChars)\n",
    "print(myChars2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we remove our non-alphabetic characters from the list of characters to eliminate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "~*(!':3/]8@0+\";65&,>_<4-7%\n",
      ".?1)9#$ [2\n"
     ]
    }
   ],
   "source": [
    "for x in lowerAlphaB:\n",
    "    myChars2 = myChars2.replace(x,'')\n",
    "    \n",
    "for x in upperAlphaB:\n",
    "    myChars2 = myChars2.replace(x,'')\n",
    "    \n",
    "print(len(myChars2))\n",
    "print(myChars2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@', ')', '0', '+', '[', '_', '9', '~', '2', '#', '<', '$', '4', '\"', '-', ';', ' ', '*', '7', '6', '%', '(', '!', \"'\", ':', '3', '\\n', '.', '5', '&', '?', '/', ']', '1', ',', '>', '8']\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "print(list(set(myChars2)))\n",
    "print(len(list(set(myChars2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the Text\n",
    "\n",
    "Again, we begin by initializing a timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tTMP = []\n",
    "tTMP.append(time.time())\n",
    "tTMP.append(\"Cleaning Text timer\")\n",
    "\n",
    "t0s.append(tTMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can eliminate these characters from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create copy of imported data\n",
    "data2 = data\n",
    "\n",
    "for x in myChars2:\n",
    "    data2 = data2.replace(x,'')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and check to make sure the lengths have changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402665\n",
      "307917\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(len(data2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, we convert all letters in the text to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data2.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Frequencies and Probabilities\n",
    "\n",
    "Before continuting, we start one more timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tTMP = []\n",
    "tTMP.append(time.time())\n",
    "tTMP.append(\"Frequencies timer\")\n",
    "\n",
    "t0s.append(tTMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequencies\n",
    "\n",
    "To get the Frequencies of each letter, we first create an array to store them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then go though the alphabet counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24352, 5221, 6873, 15302, 37080, 6270, 6841, 19997, 19642, 692, 3138, 12565, 7444, 20959, 24325, 4950, 194, 16092, 18376, 29970, 9340, 2474, 8244, 387, 7032, 157]\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "for x in lowerAlpha:\n",
    "    counts.append(data2.count(x))\n",
    "    \n",
    "print(counts)\n",
    "print(len(counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can compute the probabilities.  First, we store the number of characters in the cleaned text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307917\n"
     ]
    }
   ],
   "source": [
    "charTOT = len(data2)\n",
    "\n",
    "print(charTOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which we check against the frequencies we just calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307917\n"
     ]
    }
   ],
   "source": [
    "print(sum(counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilities\n",
    "\n",
    "Again, we start a timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tTMP = []\n",
    "tTMP.append(time.time())\n",
    "tTMP.append(\"Probabilities timer\")\n",
    "\n",
    "t0s.append(tTMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we, again, first create and empty array to hold the probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prbs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then we loop through the list of frequencies, using them to create each probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in counts:\n",
    "    prbs.append(x / charTOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this gives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07908624726793259, 0.016955867977409497, 0.022320950126170365, 0.049695210072844304, 0.12042206178937831, 0.02036263018930426, 0.022217026016751268, 0.0649428255016774, 0.0637899174128093, 0.002247358866187966, 0.01019105797991017, 0.04080645108909219, 0.02417534595361737, 0.068067044041089, 0.07899856130061023, 0.01607576067576652, 0.0006300399133532738, 0.05226083652412825, 0.05967841983391628, 0.09733142372782276, 0.03033284943669885, 0.008034632709463915, 0.02677344868909479, 0.0012568321982872007, 0.0228373230448465, 0.0005098776618374432]\n"
     ]
    }
   ],
   "source": [
    "print(prbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy Estimate\n",
    "\n",
    "We start one last timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tTMP = []\n",
    "tTMP.append(time.time())\n",
    "tTMP.append(\"Entropy timer\")\n",
    "\n",
    "t0s.append(tTMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now estimate the entropy of the converted text (*all lower case, no special characters, spaces, tabs, or returns*).  To do this, we first initialize a variable to hold our value for the entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropTOT = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we loop through all the probabilities, computing the entropy for each and adding it to the total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in prbs:\n",
    "    entropTOT = entropTOT - x * math.log2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.184820826080936\n"
     ]
    }
   ],
   "source": [
    "print(entropTOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "numTimers = len(t0s)\n",
    "print(numTimers)\n",
    "\n",
    "tTOTs = []\n",
    "for i in range(numTimers):\n",
    "    tARR = t0s[i]\n",
    "    \n",
    "    tTMP = tARR[0]\n",
    "    tNEW = t1 - tTMP\n",
    "    \n",
    "    aSTR = tARR[1]\n",
    "    \n",
    "    tmp = []\n",
    "    tmp.append(aSTR)\n",
    "    tmp.append(tNEW)\n",
    "    \n",
    "    tTOTs.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start timer :  0.2948160171508789 seconds\n",
      "Load File timer :  0.23638916015625 seconds\n",
      "Get Character List timer :  0.18616294860839844 seconds\n",
      "Cleaning Text timer :  0.14438295364379883 seconds\n",
      "Frequencies timer :  0.10405707359313965 seconds\n",
      "Probabilities timer :  0.06135296821594238 seconds\n",
      "Entropy timer :  0.03586411476135254 seconds\n"
     ]
    }
   ],
   "source": [
    "for i in range(numTimers):\n",
    "    tmp = tTOTs[i]\n",
    "    \n",
    "    print(tmp[0] + ' :  ' + str(tmp[1]) + ' seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 (b)\n",
    "\n",
    "## Definitions\n",
    "\n",
    "Prior to beginning our work, we load the requiste packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and start a timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0s = []\n",
    "\n",
    "tTMP = []\n",
    "tTMP.append(time.time())\n",
    "tTMP.append(\"Start timer\")\n",
    "\n",
    "t0s.append(tTMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also load all 26 letters (*in lower case*) into an array for later use.  This is done by importing a text file containing these letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('LowerCaseAlphabet.txt', 'r') as myFile:\n",
    "    lowerAlpha = myFile.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then stripping the return characters (*\\n*) from each line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(lowerAlpha)):\n",
    "    lowerAlpha[i] = lowerAlpha[i].replace('\\n','')\n",
    "\n",
    "lowerAlphaB = ''.join(str(x) for x in lowerAlpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we check to see if the alphabet imported properly,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "print(lowerAlphaB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as well as create an upper case version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "upperAlpha = []\n",
    "for x in lowerAlpha:\n",
    "    upperAlpha.append(x.upper())\n",
    "    \n",
    "upperAlphaB = ''.join(str(x) for x in upperAlpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and check it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABCDEFGHIJKLMNOPQRSTUVWXYZ\n"
     ]
    }
   ],
   "source": [
    "print(upperAlphaB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load File\n",
    "\n",
    "First we start another timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tTMP = []\n",
    "tTMP.append(time.time())\n",
    "tTMP.append(\"Load File timer\")\n",
    "\n",
    "t0s.append(tTMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we begin our work by loading the text from the source file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Text-Files/sawyer-ascii.txt', 'r') as myFile:\n",
    "    tempData = myFile.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we get some basic information about the data imported from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8807\n"
     ]
    }
   ],
   "source": [
    "print(len(tempData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, convert the array of strings to a single string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ''.join(str(x) for x in tempData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then find and store the length of the resulting string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402665\n"
     ]
    }
   ],
   "source": [
    "charCNT = len(data)\n",
    "print(charCNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the length compare it to the combined length of all the strings in the initial array we got from importing the text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402665\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for x in tempData:\n",
    "    cnt = cnt + len(x)\n",
    "\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the character counts are accurate, we can proceed.\n",
    "\n",
    "\n",
    "## Get Character List\n",
    "\n",
    "First, we start yet another timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tTMP = []\n",
    "tTMP.append(time.time())\n",
    "tTMP.append(\"Get Character List timer\")\n",
    "\n",
    "t0s.append(tTMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will obtain a list of all characters occuring in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', '~', 'i', 'G', 'M', 'c', '*', '(', 'T', '!', \"'\", ':', '3', '/', ']', 'B', '8', '@', 'u', 'v', 'U', '0', '+', 'e', '\"', 'I', 'd', ';', 'P', 'W', '6', 'J', 'Q', 'E', 'N', 'z', '5', '&', 'w', 'p', 'R', ',', '>', 'k', 'A', 'm', 'K', '_', 'L', '<', 'f', '4', '-', 'n', 'b', '7', 'O', 'q', 'j', '%', 'l', 'a', 'D', '\\n', 'h', '.', 't', 'X', '?', '1', 'y', ')', '9', '#', 'o', 'g', '$', 'S', ' ', 'r', 's', 'F', 'Y', 'H', 'x', 'V', '[', '2']\n",
      "C~iGMc*(T!':3/]B8@uvU0+e\"Id;PW6JQENz5&wpR,>kAmK_L<f4-nb7Oqj%laD\n",
      "h.tX?1y)9#og$S rsFYHxV[2\n"
     ]
    }
   ],
   "source": [
    "myChars = list(set(data))\n",
    "\n",
    "myChars2 = ''.join(str(x) for x in myChars)\n",
    "print(myChars)\n",
    "print(myChars2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we remove our non-alphabetic characters from the list of characters to eliminate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "~*(!':3/]8@0+\";65&,>_<4-7%\n",
      ".?1)9#$ [2\n"
     ]
    }
   ],
   "source": [
    "for x in lowerAlphaB:\n",
    "    myChars2 = myChars2.replace(x,'')\n",
    "    \n",
    "for x in upperAlphaB:\n",
    "    myChars2 = myChars2.replace(x,'')\n",
    "    \n",
    "print(len(myChars2))\n",
    "print(myChars2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@', ')', '0', '+', '[', '_', '9', '~', '2', '#', '<', '$', '4', '\"', '-', ';', ' ', '*', '7', '6', '%', '(', '!', \"'\", ':', '3', '\\n', '.', '5', '&', '?', '/', ']', '1', ',', '>', '8']\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "print(list(set(myChars2)))\n",
    "print(len(list(set(myChars2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the Text\n",
    "\n",
    "Again, we begin by initializing a timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tTMP = []\n",
    "tTMP.append(time.time())\n",
    "tTMP.append(\"Cleaning Text timer\")\n",
    "\n",
    "t0s.append(tTMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can eliminate these characters from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create copy of imported data\n",
    "data2 = data\n",
    "\n",
    "for x in myChars2:\n",
    "    data2 = data2.replace(x,'')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and check to make sure the lengths have changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402665\n",
      "307917\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(len(data2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, we convert all letters in the text to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data2.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate N-Grams\n",
    "\n",
    "For the next part, we will need lists of Bi-Grams and Tri-Grams based off the lowercase english alphabet.  We start by defining a generating function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genNgrams(dictIn, nIn):\n",
    "    gramsOut = []\n",
    "    \n",
    "    if (nIn == 1):\n",
    "        for char in dictIn:\n",
    "            gramsOut.append(char)\n",
    "    else:\n",
    "        gramsNm1in = genNgrams(dictIn, (nIn-1))\n",
    "        \n",
    "        for char in dictIn:\n",
    "            for aStr in gramsNm1in:\n",
    "                tmp = char + aStr\n",
    "                gramsOut.append(tmp)\n",
    "    \n",
    "    return gramsOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-Grams\n",
    "\n",
    "We begin with the array of lowercase alphabetic characters for the english language; however, we must first define an empty array to hold the Bi-Grams that we will generate.  After which, we loop through the lowercase alphabet twice, joining each pair and appending the new pair to our array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676\n"
     ]
    }
   ],
   "source": [
    "myBiGrams = genNgrams(lowerAlpha, 2)\n",
    "print(len(myBiGrams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking that the number of Bi-Grams we generated is correct, we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676\n"
     ]
    }
   ],
   "source": [
    "print(26 ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tri-Grams\n",
    "\n",
    "Again, we begin with the array of lowercase alphabetic characters for the english language; however, we must first define an empty array to hold the Tri-Grams that we will generate.  After which, we loop through the lowercase alphabet three times, joining each triplet and appending the new triplet to our array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17576\n"
     ]
    }
   ],
   "source": [
    "myTriGrams = genNgrams(lowerAlpha, 3)\n",
    "print(len(myTriGrams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking that the number of Bi-Grams we generated is correct, we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17576\n"
     ]
    }
   ],
   "source": [
    "print(26 ** 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quad-Grams\n",
    "\n",
    "Again, we begin with the array of lowercase alphabetic characters for the english language; however, we must first define an empty array to hold the Quad-Grams that we will generate.  After which, we loop through the lowercase alphabet four times, joining each quadruplet and appending the new quadruplet to our array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456976\n"
     ]
    }
   ],
   "source": [
    "myQuadGrams = genNgrams(lowerAlpha, 4)\n",
    "print(len(myQuadGrams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking that the number of Bi-Grams we generated is correct, we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456976\n"
     ]
    }
   ],
   "source": [
    "print(26 ** 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pent-Grams\n",
    "\n",
    "Again, we begin with the array of lowercase alphabetic characters for the english language; however, we must first define an empty array to hold the Pent-Grams that we will generate.  After which, we loop through the lowercase alphabet five times, joining each pentuplet and appending the new pentuplet to our array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11881376\n"
     ]
    }
   ],
   "source": [
    "myPentGrams = genNgrams(lowerAlpha, 5)\n",
    "print(len(myPentGrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11881376\n"
     ]
    }
   ],
   "source": [
    "print(26 ** 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Frequencies and Probabilities\n",
    "\n",
    "### Frequencies\n",
    "\n",
    "To get the Frequencies of each letter, we first create an arrays to store them for Uni-Grams, Bi-Grams, Tri-Grams, Quad-Grams, and Pent-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = []\n",
    "cntsBI= []\n",
    "cntsTRI = []\n",
    "cntsQUAD = []\n",
    "cntsPENT = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then go through the alphabet counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "[24352, 5221, 6873, 15302, 37080, 6270, 6841, 19997, 19642, 692, 3138, 12565, 7444, 20959, 24325, 4950, 194, 16092, 18376, 29970, 9340, 2474, 8244, 387, 7032, 157]\n"
     ]
    }
   ],
   "source": [
    "for x in lowerAlpha:\n",
    "    counts.append(data2.count(x))\n",
    "    \n",
    "print(len(counts))\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then go though the Bi-Grams counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676\n"
     ]
    }
   ],
   "source": [
    "for x in myBiGrams:\n",
    "    cntsBI.append(data2.count(x))\n",
    "    \n",
    "print(len(cntsBI))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then the Tri-Grams counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17576\n"
     ]
    }
   ],
   "source": [
    "for x in myTriGrams:\n",
    "    cntsTRI.append(data2.count(x))\n",
    "    \n",
    "print(len(cntsTRI))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then the Quad-Grams counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456976\n"
     ]
    }
   ],
   "source": [
    "for x in myQuadGrams:\n",
    "    cntsQUAD.append(data2.count(x))\n",
    "    \n",
    "print(len(cntsQUAD))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and finally the Pent-Grams counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-43138550546a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmyPentGrams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mcntsPENT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcntsPENT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for x in myPentGrams:\n",
    "    cntsPENT.append(data2.count(x))\n",
    "    \n",
    "print(len(cntsPENT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character and N-Gram totals\n",
    "\n",
    "Now, we can compute the probabilities.  First, we store the number of characters in the cleaned text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charTOT = len(data2)\n",
    "\n",
    "print(charTOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which we check against the frequencies we just calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we compute the number of Bi-, Tri-, and Quad- Grams based on the total number of characters in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biTOT = math.floor(charTOT / 2)\n",
    "triTOT = math.floor(charTOT / 3)\n",
    "quadTOT = math.floor(charTOT / 4)\n",
    "pentTOT = math.floor(charTOT / 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which gives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(biTOT)\n",
    "print(triTOT)\n",
    "print(quadTOT)\n",
    "print(pentTOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilities\n",
    "\n",
    "Again, we first create and empty array to hold the probabilities for single characters, as well as all our N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prbs = []\n",
    "biPRBS = []\n",
    "triPRBS = []\n",
    "quadPRBS = []\n",
    "pentPRBS = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then we loop through the list of frequencies, using them to create each probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in counts:\n",
    "    prbs.append(x / charTOT)\n",
    "    \n",
    "for x in cntsBI:\n",
    "    biPRBS.append(x / biTOT)\n",
    "        \n",
    "for x in cntsTRI:\n",
    "    triPRBS.append(x / triTOT)\n",
    "    \n",
    "for x in cntsQUAD:\n",
    "    quadPRBS.append(x / quadTOT)        \n",
    "    \n",
    "for x in cntsPENT:\n",
    "    pentPRBS.append(x / pentTOT)\n",
    "    \n",
    "print(len(prbs))\n",
    "print(len(biPRBS))\n",
    "print(len(triPRBS))\n",
    "print(len(quadPRBS))\n",
    "print(len(pentPRBS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for single characters, this gives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy Estimate\n",
    "\n",
    "### Single Characters\n",
    "\n",
    "We can now estimate the entropy of the converted text (*all lower case, no special characters, spaces, tabs, or returns*).  To do this, we first initialize a variable to hold our value for the entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropTOT = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we loop through all the probabilities, computing the entropy for each and adding it to the total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in prbs:\n",
    "    entropTOT = entropTOT - x * math.log2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(entropTOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-Grams\n",
    "\n",
    "For Bi-Grams, we first initialize a variable to hold our value for the entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biEntropTOT = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we loop through all the Bi-Gram Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testI = 0\n",
    "for x in biPRBS:\n",
    "    testI += 1\n",
    "    \n",
    "    if x == 0.0:\n",
    "        biEntropTOT = biEntropTOT\n",
    "    else:\n",
    "        biEntropTOT = biEntropTOT - x * math.log2(x)\n",
    "\n",
    "        \n",
    "print(testI)\n",
    "print(biEntropTOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tri-Grams\n",
    "\n",
    "For Tr-Grams, we first initialize a variable to hold our value for the entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triEntropTOT = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we loop through all the Tri-Gram Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testI = 0\n",
    "for x in triPRBS:\n",
    "    testI += 1\n",
    "    \n",
    "    if x == 0.0:\n",
    "        triEntropTOT = triEntropTOT\n",
    "    else:\n",
    "        triEntropTOT = triEntropTOT - x * math.log2(x)\n",
    "\n",
    "        \n",
    "print(testI)\n",
    "print(triEntropTOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quad-Grams\n",
    "\n",
    "For Quad-Grams, we first initialize a variable to hold our value for the entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quadEntropTOT = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we loop through all the Qaud-Gram Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testI = 0\n",
    "for x in quadPRBS:\n",
    "    testI += 1\n",
    "    \n",
    "    if x == 0.0:\n",
    "        quadEntropTOT = quadEntropTOT\n",
    "    else:\n",
    "        quadEntropTOT = quadEntropTOT - x * math.log2(x)\n",
    "\n",
    "        \n",
    "print(testI)\n",
    "print(quadEntropTOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pent-Grams\n",
    "\n",
    "For Pent-Grams, we first initialize a variable to hold our value for the entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pentEntropTOT = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we loop through all the Qaud-Gram Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testI = 0\n",
    "for x in pentPRBS:\n",
    "    testI += 1\n",
    "    \n",
    "    if x == 0.0:\n",
    "        pentEntropTOT = pentEntropTOT\n",
    "    else:\n",
    "        pentEntropTOT = pentEntropTOT - x * math.log2(x)\n",
    "\n",
    "        \n",
    "print(testI)\n",
    "print(pentEntropTOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Times\n",
    "\n",
    "Overall, it took"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 (c)\n",
    "\n",
    "If the entropy is estimated using Tri-Grams instead of Bi-Grams, the estimate of the entropy will be higher than the estimate calcuated using Bi-Grams.  This is due to the fact that the alphabet size is larger for Tri-Grams compared with Bi-Grams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "\n",
    "We begin, as always, by importing required libraries followed by defining any functions we are going to create for later use.\n",
    "\n",
    "## Library Imports\n",
    "\n",
    "For this implementation, we will require Python's \"*heapq*\" library so that we can create a priority que."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need the \"csv\" library so that we can read and write CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will need \"time\" library so that we can determine how long the compression and decompression processes run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have imported all the required libraries, we can move on to defining **_OUR_** functions and subroutines.\n",
    "\n",
    "## Function Definitions\n",
    "\n",
    "We will need several functions of our own to both allow us to endcode/decode using Huffman codes, as a well as to make the later code easier to read and write by moving simple and/or repeated tasks to subroutines of their own.  These subroutines are \n",
    "\n",
    "* File Reader (*for text files*)\n",
    "* File Writer (*for text files*)\n",
    "* File Reader (*for CSV files*)\n",
    "* File Writer (*for CSV files*)\n",
    "* Dictionary Extractor\n",
    "* N-Gram Generator\n",
    "* Freqency Counter\n",
    "* Huffman Tree Maker\n",
    "* Huffman Code Builder\n",
    "\n",
    "We will also need an object class for\n",
    "\n",
    "* Huffman Nodes\n",
    "\n",
    "### File Reader (*for text files*)\n",
    "\n",
    "We start with the **File Reader** for text files.  We will name it _**fileRDR**_ and its code is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileRDR(filename):\n",
    "    with open(filename, 'r') as myTextFileIn:\n",
    "        myTextIn = myTextFileIn.read();\n",
    "    \n",
    "        myTextFileIn.close()\n",
    "        \n",
    "    \n",
    "    return myTextIn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the text file reader is done, we move on to the next subroutine.\n",
    "\n",
    "### File Writer (*for text files*)\n",
    "\n",
    "We continue with the **File Writer** for text files.  We will name it _**fileWTR**_ and its code is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileWTR(filename, strToWrite):\n",
    "    with open(filename, 'w') as myTextFileOut:\n",
    "        myTextFileOut.write(strToWrite)\n",
    "        \n",
    "        myTextFileOut.close()\n",
    "        \n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the text writer works, we move on to CSV file readers and writers.\n",
    "\n",
    "### File Reader (*for CSV files*)\n",
    "\n",
    "Now, we will create a **File Reader** for CSV files.  We will name it _**csvFileRDR**_ and its code is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csvFileRDR(filename):\n",
    "    csvOUT = []\n",
    "    \n",
    "    with open(filename, 'r') as myCSVfileIn:\n",
    "        csvReader = csv.reader(x for x in myCSVfileIn)\n",
    "        \n",
    "        for row in csvReader:\n",
    "            temp = row\n",
    "            csvOUT.append(temp)\n",
    "            \n",
    "        myCSVfileIn.close()\n",
    "        \n",
    "        \n",
    "    return csvOUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the CSV reader works, we move on to the CSV writer.\n",
    "\n",
    "### File Writer (*for CSV files*)\n",
    "\n",
    "Now, we will create a **File Writer** for CSV files.  We will name it _**csvFileWTR**_ and its code is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csvFileWTR(filename, arrayToWrite):\n",
    "    with open(filename, 'w', newline='') as myCSVfileOut:\n",
    "        csvWriter = csv.writer(myCSVfileOut, delimiter=',',\n",
    "                            quotechar=' ', quoting=csv.QUOTE_MINIMAL)\n",
    "                               #dialect='excel')\n",
    "                               #delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        \n",
    "        for row in arrayToWrite:\n",
    "            csvWriter.writerow(row)\n",
    "            \n",
    "        myCSVfileOut.close()\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary Extractor\n",
    "\n",
    "We will also need a subroutine to extract a dictionary of all the characters used by a specified text.  Thus, we create the **dictExtractr** sub-routine to extract a character dictionary from the input String provided to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictExtractr(textIn):\n",
    "    dictOut = list(set(textIn))\n",
    "    \n",
    "    return dictOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dictionary exractor works, we will new move on to the N-Gram Generator.\n",
    "\n",
    "### N-Gram Generator\n",
    "\n",
    "Since we may wish to encode based on Bi-Grams, Tri-Grams, or some other type of N-Grams (*instead of just characters*), we need to write a routine to create N-Grams of the specified dimension (*N*) from a specified character dictionary.  We call this function **nGramBuilder** and its code is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nGramBuilder(nIn, dictIn):\n",
    "    gramsOut = []\n",
    "    \n",
    "    if nIn == 1:\n",
    "        gramsOut = dictIn\n",
    "    else: #if nIn > 1:\n",
    "        nOut = nIn - 1\n",
    "        \n",
    "        tempGrams = nGramBuilder(nOut, dictIn)\n",
    "        \n",
    "        for letter in dictIn:\n",
    "            for gram in tempGrams:\n",
    "                gramsOut.append(letter + gram)\n",
    "                \n",
    "    \n",
    "    return gramsOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our character dictionary is used by one more function which we will define next\n",
    "\n",
    "### Frequency Counter\n",
    "\n",
    "We need to know the frequency of characters from a given dictionary in a given document.  Thus, we create the **freqCTR** sub-routine to determine these frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freqCTR(dictIn, textIn):\n",
    "    counts = []\n",
    "    \n",
    "    for x in dictIn:\n",
    "        counts.append(textIn.count(x))\n",
    "        \n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freqCTR(dictIn, textIn):\n",
    "    counts = {}\n",
    "    \n",
    "    for x in dictIn:\n",
    "        counts[x] = textIn.count(x)\n",
    "        \n",
    "        \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, before continuing with subroutines and functions, we need to define an object class for Huffman Nodes (*nodes in our Huffman tree(s)*).\n",
    "\n",
    "### Huffman Nodes\n",
    "\n",
    "Our object for representing Huffman Nodes will be called the **HuffmanNode** class and must have the properties \n",
    "\n",
    "* The character it represents: **_myChar_**\n",
    "    * *Data-Type: __char__*\n",
    "    * (*Default = __None__*)\n",
    "* The frequency of the character it represents: **_myFreq_**\n",
    "    * *Data-Type: __int__*\n",
    "    * (*Default = Not specified*)\n",
    "* The left child of the node: **_myLeft_**\n",
    "    * *Data-Type: __HuffmanNode__*\n",
    "    * (*Default = __None__*)\n",
    "* The right child of the node: **_myRight_**\n",
    "    * *Data-Type: __HuffmanNode__*\n",
    "    * (*Default = __None__*)\n",
    "    \n",
    "The **HuffmanNode** class must also have a method for comparing it to other instances of **HuffmanNode** and another method to allow an instance of **HuffmanNode** to determine if it is a leaf in a tree (*myLeft = None __and__ myRight = None*).  With all this in mind, we define our **HuffmanNode** class as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuffmanNode(object):\n",
    "    def __init__(self, theFreq, theChar=None, theLeft=None, theRight=None):\n",
    "        self.myChar = theChar\n",
    "        self.myFreq = theFreq\n",
    "        self.myLeft = theLeft\n",
    "        self.myRight = theRight\n",
    "        \n",
    "    def __lt__(self, other):\n",
    "        return self.myFreq < other.myFreq\n",
    "    \n",
    "    def isLeaf(self):\n",
    "        return (self.myLeft == None  and  self.myRight == None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the **HuffmanNode** object class tests out properly, we move on to creating a method to build a Huffman Tree.\n",
    "\n",
    "### Huffman Tree Maker\n",
    "\n",
    "Given some frequency data about the occurance of character in some text, where the data is in the form *{__char__ (or str): __count__}*, we want a method which will create a corresponding Huffman Tree.  Thus, the method must first convert each element of the provided data to its own instance of the **HuffmanNode** class; after which it sequentially builds a HuffmanTree (*itself a Huffman Node*) by successively combining the two nodes with the lowest frequency values into a new instance of a **HuffmanNode** which has these two nodes as children and a frequency equal to the sum of the frequencies of its children.  Since we are working from the \"*bottom*\" of the pile of frequencies up, we will utilize the **heapify**, **heappop**, and **heappush** methods from the \"*heapq*\" library to allow us to implement this as a reverse priority que.  Thus, we define the method **hTreeMakr** as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hTreeMakr(theFreqData):\n",
    "    myFreqData = theFreqData\n",
    "    \n",
    "    hNodes = []\n",
    "    \n",
    "    for char in myFreqData:\n",
    "        hNodes.append(HuffmanNode(myFreqData[char], char))\n",
    "        \n",
    "    heapq.heapify(hNodes)\n",
    "    \n",
    "    while(len(hNodes) > 1):\n",
    "        leftLeaf = heapq.heappop(hNodes)\n",
    "        rightLeaf = heapq.heappop(hNodes)\n",
    "        \n",
    "        newFreq = leftLeaf.myFreq + rightLeaf.myFreq\n",
    "        \n",
    "        newNode = HuffmanNode(newFreq, theLeft = leftLeaf, theRight = rightLeaf)\n",
    "        \n",
    "        heapq.heappush(hNodes, newNode)\n",
    "        \n",
    "    \n",
    "    return None if hNodes == [] else heapq.heappop(hNodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the **hTreeMakr** method tests properly, we move on to our *last* sub-routine.\n",
    "\n",
    "### Code Creator\n",
    "\n",
    "The last *sub-routine* we need is one which will convert **HuffmanTrees** into a code index (*dictionary*).  We call this method **codeFromHtree** and its code is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def codeFromHtree(hTree):\n",
    "    code = dict()\n",
    "    \n",
    "    def bldCode(hNode, codeNow = ''):\n",
    "        \n",
    "        if (hNode == None):\n",
    "            return\n",
    "        \n",
    "        if (hNode.myLeft == None and hNode.myRight == None):\n",
    "            code[hNode.myChar] = codeNow\n",
    "            \n",
    "        bldCode(hNode.myLeft, codeNow + \"0\")\n",
    "        bldCode(hNode.myRight, codeNow + \"1\")\n",
    "        \n",
    "        \n",
    "    bldCode(hTree)\n",
    "    \n",
    "    \n",
    "    return code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this sub-routine correctly built all the codes in its tests, we can now move on to the actually programs for encoding and decoding.\n",
    "\n",
    "## Encoder\n",
    "\n",
    "We will now create a method to handle the entire encoding process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(textIn):\n",
    "    textDict = dictExtractr(textIn)\n",
    "    \n",
    "    freqs = freqCTR(textDict, textIn)\n",
    "    \n",
    "    myHtree = hTreeMakr(freqs)\n",
    "    \n",
    "    code = codeFromHtree(myHtree)\n",
    "    \n",
    "    encodedText = \"\"\n",
    "    for char in textIn:\n",
    "        encodedText += code[char]\n",
    "        \n",
    "    return encodedText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on Tom Sawyer\n",
    "\n",
    "First we start a timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we import the Tom Sawyer Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tomText = fileRDR('../Text-Files/sawyer-ascii.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "followed by encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tomCompressed = encode(tomText)\n",
    "print(len(tomCompressed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and stopping the timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The compression ratio is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tomCompressed)/(8*len(tomText)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the elapsed time is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tComp = t1 - t0\n",
    "print(tComp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on the King James Version of the Bible\n",
    "\n",
    "First we start a timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we import the Tom Sawyer Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bibleText = fileRDR('../Text-Files/kingJames-ascii.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "followed by encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bibleCompressed = encode(bibleText)\n",
    "print(len(bibleCompressed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and stopping the timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The compression ratio is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(bibleCompressed)/(8*len(bibleText)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the elapsed time is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tComp = t1 - t0\n",
    "print(tComp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "\n",
    "Last, we will write a decoder method to decode encoded text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(textIn, freqsIn):\n",
    "    hTree = hTreeMakr(freqsIn)\n",
    "    \n",
    "    decoded = \"\"\n",
    "    currentNode = hTree\n",
    "    for compCode in textIn:\n",
    "        if (compCode == \"0\"):\n",
    "            currentNode = currentNode.myLeft\n",
    "        else:\n",
    "            currentNode = currentNode.myRight\n",
    "            \n",
    "        if (currentNode.isLeaf()):\n",
    "            decoded += currentNode.myChar\n",
    "            currentNode = hTree\n",
    "            \n",
    "            \n",
    "    return decoded    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on Tom Sawyer\n",
    "\n",
    "Get frequencies for passing to the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqsToDecomp = freqCTR(dictExtractr(tomText), tomText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start a timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decompress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tomDecomp = decoder(tomCompressed, freqsToDecomp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stop the timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and compare the lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tomDecomp))\n",
    "print(len(tomText))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tomDecomp == tomText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and, finally, compute the elapse time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totTime = t1 - t0\n",
    "print(totTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on The King James version of the Bible\n",
    "\n",
    "Get frequencies for passing to the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqsToDecomp = freqCTR(dictExtractr(bibleText), bibleText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start a timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decompress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bibleDecomp = decoder(bibleCompressed, freqsToDecomp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stop the timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and compare the lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(bibleDecomp))\n",
    "print(len(bibleText))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bibleDecomp == bibleText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and, finally, compute the elapse time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totTime = t1 - t0\n",
    "print(totTime)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
